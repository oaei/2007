<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
           "http://www.w3.org/TR/REC-html40/loose.dtd">
<head>
  <title>OAEI2007 - Anatomy Results</title>
  <link rel="stylesheet" type="text/css" href="../../anatomy/style.css" />
  <meta http-equiv="content-type" content="text/html; charset=iso-8859-1" />
</head>

<body>

<h1>Track: Anatomy - OAEI 2007 - Results</h1>

<p class="important"><b>Some of the runtime measurements are not correctly presented in the the current version of the OAEI results-paper. The results presented here are corrected with respect to these mistakes and the results-paper will also be fixed at a later time.</b></p>

<h2>Test Data and Experimental Setting</h2>
<p>
The ontologies of the antomy track are the NCI Thesaurus describing
the human anatomy, published by <a href="http://www.cancer.gov/cancerinfo/terminologyresources/">
the National Cancer Institute (NCI)</a>
and the<a href="http://www.informatics.jax.org/searches/AMA_form.shtml">
Adult Mouse Anatomical Dictionary</a>
which has been developed as part of the Mouse Gene Expression
Database project. Both resources are part of the Open Biomedical
Ontologies (OBO). We gratefully thank Martin Ringwald and Terry
Hayamizu for providing the reference alignment for these ontologies.
The complex and laborious task of generating the reference alignment
has been conducted by a combination of computational methods and
extensive manual evaluation. In addition, the ontologies were
extended and harmonized to increase the number of mappings between
both ontologies.
</p>

<p>
The task is placed in a  domain where we find large, carefully
designed ontologies that are described in technical terms. Besides
their large size and a conceptualization that is only to a limited
degree based on the use of natural language, they also differ from
other ontologies with respect to the use of specific annotations and
roles, e.g. the extensive use of the <i>partOf</i> relation. The
manual harmonization of the ontologies leads to a
situation, where we have a high number of rather trivial mappings
that can be found by simple string comparison techniques. At the
same time, we have a good share of non-trivial mappings that require
a careful analysis and sometimes also medical background knowledge.
To better understand the occurrence of non-trivial correspondences
in alignment results, we implemented a straight forward matching
tool that compares normalized concept labels. This trivial matcher
generates for all pairs of concepts <font face="symbol">
&#225;</font> C, D<font face="symbol">
&#241;</font> a correspondence if and only if the normalized label
of C is identical to the normalized label of D. In general we
expect an alignment generated by this approach to be highly precise
while recall will be relatively low. With respect to our matching
task we measured approximately 99% precision and 60% recall.
Notice that the value for recall is relatively high, which is
partially caused by the harmonization process mentioned above.
</p>

<p>
Because we assumed that all matchers would easily find the trivial
mappings, we introduce an additional measure for recall called
<i>recall</i>+. <i>Recall</i>+ measures how many non trivial
correct correspondences can be found in an alignment M. Given
reference alignment R and alignment S generated by the naive
string equality matching, <i>recall</i>+ is defined in the
following way:
<p>

<p>
<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
<i>Recall</i>+ = | (R <font face="symbol">Ç</font
>M) <font face="symbol">-</font
> S | / | R <font face="symbol">-</font
> S |</td></tr></table>
</td></tr></table>
</p>

<p>
We divided the task of automatically generating an alignment between
these ontologies into three subtasks. Task #1 was obligatory for
participants of the anatomy track, while task #2 and #3 were
optional. For task #1 the matching system has to be applied with
standard settings to obtain a result that is as good as possible
with respect to the expected f-value. For task #2 an alignment with
increased precision has to be found. This seems to be an adequate
requirement in a scenario where the automatically generated
alignment will be directly used without subsequent manual
evaluation. Contrary to this approach, in task #3 an alignment with
increased recall has to be generated. Such an alignment could be
seen as basis for subsequent expert evaluation. We believe that
systems configurable with respect to these requirements will be much
more useful in concrete scenarios compared to static systems.
</p>

<h2>Main Results</h2>
<p>
In total, eleven systems participated in the anatomy task. These
systems can be roughly divided in three groups. Systems of type A
are highly specialized on matching biomedical ontologies and make
extensive use of medical background knowledge. These systems are
AOAS  and Sambo. Systems of type B can solve
matching problems of different domains, but include a component
exploiting biomedical background knowledge (e.g. using UMLS as
lexical reference system). Asmov  and RiMOM  fall into
this category. Systems of type C, finally can be seen as all-round
matching systems that do not distinguish between medical ontologies
and ontologies of different domains. Most systems in the experiment
fell into this category. Table  gives an
overview of participating systems.
</p>

<p class="important">*Due to some mistakes in the evaluation process, the runtimes for SAMBO and ASMOV have been confunded. Note that SAMBO runs approx. 6h for track #1 and ASMOV runs 15 hours (for preliminary results it was 7 days) for track #1 (and not vice versa). The information published before 16.10.2007 on this page was not correct and has now been corrected.</p>

<table width="80%" border="1">
<tr><td>System </td><td align="center">Type </td><td colspan="4" align="center">Testcase #1 </td><td colspan="2" align="center">Testcase #2 </td><td colspan="2" align="center">Testcase #3 </td><td colspan="2" align="center">Recall+    </td></tr>
<tr><td>&nbsp;</td><td align="center">&nbsp;</td><td align="center">Runtime </td><td align="center">Prec </td><td align="center">Rec </td><td align="center">F-val </td><td align="center">Prec </td><td align="center">Rec </td><td align="center">Prec </td><td align="center">Rec </td><td align="center">#1 </td><td align="center">#3 </td></tr><tr><td></td></tr>
<tr><td>AOAS           </td><td align="center">A </td><td align="center">n.a.   </td><td align="center">0.928 </td><td align="center">0.804 </td><td align="center">0.861 </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">0.505 </td><td align="center">-     </td></tr>
<tr><td>Sambo          </td><td align="center">A </td><td align="center">6 h </td><td align="center">0.845 </td><td align="center">0.786 </td><td align="center">0.815 </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">0.580 </td><td align="center">-     </td></tr>
<tr><td>ASMOV          </td><td align="center">B </td><td align="center">15 h *   </td><td align="center">0.803 </td><td align="center">0.701 </td><td align="center">0.749 </td><td align="center">0.870 </td><td align="center">0.696 </td><td align="center">0.739 </td><td align="center">0.705 </td><td align="center">0.270 </td><td align="center">0.284 </td></tr>
<tr><td>RiMOM          </td><td align="center">B </td><td align="center">4 h    </td><td align="center">0.377 </td><td align="center">0.659 </td><td align="center">0.480 </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">0.390 </td><td align="center">-     </td></tr><tr><td></td></tr>
<tr><td><i>- Label Eq. -     </td><td align="center"><i>- </td><td align="center"><i>3 min </td><td align="center"><i>0.987 </td><td align="center"><i>0.605 </td><td align="center"><i>0.750 </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">0.0     </td><td align="center">-     </td></tr><tr><td></td></tr>
<tr><td>Falcon-AO      </td><td align="center">C </td><td align="center">12 min </td><td align="center">0.964 </td><td align="center">0.591 </td><td align="center">0.733 </td><td align="center">0.986 </td><td align="center">0.540 </td><td align="center">0.814 </td><td align="center">0.655 </td><td align="center">0.123 </td><td align="center">0.280 </td></tr>
<tr><td>TaxoMap        </td><td align="center">C </td><td align="center">5 h   </td><td align="center">0.596 </td><td align="center">0.732 </td><td align="center">0.657 </td><td align="center">0.985 </td><td align="center">0.642 </td><td align="center">-     </td><td align="center">-     </td><td align="center">0.230 </td><td align="center">-     </td></tr>
<tr><td>AgreementM.    </td><td align="center">C </td><td align="center">30 min </td><td align="center">0.558 </td><td align="center">0.635 </td><td align="center">0.594 </td><td align="center">0.930 </td><td align="center">0.286 </td><td align="center">0.424 </td><td align="center">0.651 </td><td align="center">0.262 </td><td align="center">0.302 </td></tr>
<tr><td>Prior+         </td><td align="center">C </td><td align="center">23 min </td><td align="center">0.594 </td><td align="center">0.590 </td><td align="center">0.592 </td><td align="center">0.663 </td><td align="center">0.497 </td><td align="center">0.371 </td><td align="center">0.657 </td><td align="center">0.338 </td><td align="center">0.426 </td></tr>
<tr><td>Lily           </td><td align="center">C </td><td align="center">4 days </td><td align="center">0.481 </td><td align="center">0.559 </td><td align="center">0.517 </td><td align="center">0.672 </td><td align="center">0.380 </td><td align="center">0.401 </td><td align="center">0.588 </td><td align="center">0.374 </td><td align="center">0.410 </td></tr>
<tr><td>X-SOM          </td><td align="center">C </td><td align="center">10 h   </td><td align="center">0.916 </td><td align="center">0.248 </td><td align="center">0.390 </td><td align="center">0.942 </td><td align="center">0.104 </td><td align="center">0.783 </td><td align="center">0.565 </td><td align="center">0.008 </td><td align="center">0.079 </td></tr>
<tr><td>DSSim          </td><td align="center">C </td><td align="center">75 min </td><td align="center">0.208 </td><td align="center">0.187 </td><td align="center">0.197 </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">-     </td><td align="center">0.067 </td><td align="center">-     </td></tr></i></i></i></i></i></i></table>

<p>* The runtime of the ASMOV system obtained for preliminary results was 7 days, first (some paragraphs in the text are based on this information). Meanwhile, the system has been optimized and the runtime has been reduced to approx. 15 hours for track #1, as now presented in the table.</p>

<h3>Runtime</h3>
<p>
The runtime of the systems differs significantly (Remark: Runtime
information has been provided by the participants. All alignments
have been generated on similar equipped standard PCs. Advantages
based on hardware differences could be neglected due to the
significant differences in runtime). In average type-C systems
outperformed systems that use medical knowledge. Falcon-AO, a system
that solves large matching problems by applying a partition-based
block matching strategy, solves the matching task in about 12
minutes without loss of quality with respect to the resulting
alignment compared to other systems of type C. It has to be
considered if similar approaches can also be applied to systems like
ASMOV or Lily to solve their problems with runtime.
</p>

<h3>Type-C systems</h3>
</p>
The most astounding result is based on the suprisingly good
performance of the naive label comparison approach compared to the
alignments generated by systems of type C. The results of the naive
approach are better with respect to recall as well as precision for
testcase #1 compared to almost all matching systems of type C. Only
TaxoMap and AgreementMaker generate an alignment with higher recall
but a significant loss in precision. We would have expected the
participating systems to find more correct correspondences than
applying straight forward label comparisons. It seems that many
matching systems do not accept a correspondence even if the
normalized labels of the concepts are equal. On the one hand this
might be caused by not detecting this equality at all (e.g. due to a
partition based approach). On the other hand a detected label
equality can be rejected as correspondence due to the fact that
additional information related to the concepts suggests that these
concepts have a different meaning.
</p>

<h3>Type-A/B systems</h3>
<p>
Systems that use additional background knowledge related to the
biomedical domain clearly generate better alignments compared to
type-C systems. This result conforms with our expectations.
The only exception is the low precision of the RiMOM system. The
values for <i>recall</i>+ points to the advantage of using
domain related background knowledge. Both AOAS and Sambo detect
about 50% of the non trivial correspondences, while only Lily and
Prior+ (systems of type C) achieve about 42% for testcase #3 with a significant loss
in precision. Amongst all systems the AOAS approach generates the
best alignment closely followed by Sambo. Notice that AOAS is not
available as stand alone system, but consists of a set of coupled
programs which eventually demands user configuration.
</p>

<h2>Discussion of main results</h2>
<p>
Obviously, the use of domain related background knowledge is a
crucial point in matching biomedical ontologies and the additional
effort of exploiting this knowledge pays off. This observation
supports the claims for the benefits of using background knowledge
made by other researchers . Amongst all
systems AOAS and Sambo generate the best alignments, especially the
relatively high number of detected non trivial correspondences has
to be mentioned positively. Nevertheless, for type C systems it is
possible to detect non trivial correspondences, too. In particular
the results of Lily and Prior+ on sub track #3 demonstrate this.
Thus, there also seems to be a significant potential of exploiting
knowledge encoded in the ontologies. Even if no medical background
knowledge is used, it seems to make sense to provide a configuration
that is specific to this type of domain. This is clearly
demonstrated by the fact that most of the universal matching systems
fail to find a significant number of trivial correspondences.
While in general it makes sense for a matcher not to accept all
trivial correspondences to avoid the problem of homonymy, there are
domains like the present one, however, where homonymy is not a
problem, for example because the terminology has been widely
harmonized.
</p>


<p>
One major problem of matching medical ontologies is related to their
large size. Though type C systems achieve relatively low values for
recall, matching large ontologies seems to be less problematic. On
the other hand the extensive use of domain related background
knowledge has positive effects on recall, but does not seem to scale
well. Thus, a trade-off between runtime and recall has to be found.
</p>

<p>
In further research we have to distinguish between different types
of non trivial correspondences. While for detecting some of these
correspondences domain specific knowledge seems to be indispensable,
the results indicate that there is also a large subset that can be
detected by the use of alternative methods that solely rely on
knowledge encoded in the ontologies. The distinction between
different classes of non trivial correspondences will be an
important step for combining the strengths of both domain specific
and domain independent matching systems. In summary, we can conclude
that the data set used in the anatomy track is well suited to
measure the characteristics of different matching systems with
respect to the problem of matching biomedical ontologies.
</p>

<h2>Further results</h2>

<p>
To better understand the differences and similarities between different matching approaches implemented in participating systems, we also analyzed how similar the generated results are. Therefore, we computed the Jaccard index, where A and B represent the sets of correspondences generated by the matching systems.
</p>

<p><image src="jindex.png"></p>

<p>The results for all pairs of systems (including the reference mapping and the trivial label equality matcher) are listed in the following table with respect to #1. Cells marked orange have a value higher than 0.7, while cells marked yellow have a value between 0.5 and 0.7.</p>

<table width="100%" border="1">
  <tbody>
    <tr>
      <td> </td>
      <td>Reference</td>
      <td>AOAS</td>
      <td>Sambo</td>
      <td>ASMOV</td>
      <td>RiMOM</td>
      <td>LabelEq.</td>
      <td>Falcon-AO</td>
      <td>TaxoMap</td>
      <td>AgreementM.</td>
      <td>Prior+</td>
      <td>Lily</td>
      <td>X-Som</td>
      <td>DSSim</td>
    </tr>
    <tr>
      <td>Reference</td>
      <td>-</td>
      <td style="background-color: #ffAA20;">0.756</td>
      <td style="background-color: #ffff80;">0.687</td>
      <td style="background-color: #ffff80;">0.598</td>
      <td>0.316</td>
      <td style="background-color: #ffff80;">0.600</td>
      <td style="background-color: #ffff80;">0.578</td>
      <td>0.464</td>
      <td>0.423</td>
      <td>0.420</td>
      <td>0.349</td>
      <td>0.205</td>
      <td>0.109</td>
    </tr>
    <tr>
      <td>AOAS</td>
      <td style="background-color: #ffAA20;">0.756</td>
      <td>-</td>
      <td style="background-color: #ffAA20;">0.738</td>
      <td style="background-color: #ffff80;">0.679</td>
      <td>0.308</td>
      <td style="background-color: #ffAA20;">0.706</td>
      <td style="background-color: #ffff80;">0.657</td>
      <td>0.484</td>
      <td>0.435</td>
      <td>0.416</td>
      <td>0.334</td>
      <td>0.239</td>
      <td>0.115</td>
    </tr>
    <tr>
      <td>Sambo</td>
      <td>0.687</td>
      <td style="background-color: #ffAA20;">0.738</td>
      <td>-</td>
      <td style="background-color: #ffff80;">0.573</td>
      <td>0.302</td>
      <td style="background-color: #ffff80;">0.576</td>
      <td style="background-color: #ffff80;">0.562</td>
      <td>0.443</td>
      <td>0.401</td>
      <td>0.407</td>
      <td>0.326</td>
      <td>0.206</td>
      <td>0.103</td>
    </tr>
    <tr>
      <td>ASMOV</td>
      <td style="background-color: #ffff80;">0.598</td>
      <td style="background-color: #ffff80;">0.679</td>
      <td style="background-color: #ffff80;">0.573</td>
      <td>-</td>
      <td>0.282</td>
      <td style="background-color: #ffff80;">0.681</td>
      <td style="background-color: #ffff80;">0.620</td>
      <td>0.461</td>
      <td>0.408</td>
      <td>0.376</td>
      <td>0.297</td>
      <td>0.232</td>
      <td>0.106</td>
    </tr>
    <tr>
      <td>RiMOM</td>
      <td>0.316</td>
      <td>0.308</td>
      <td>0.302</td>
      <td>0.282</td>
      <td>-</td>
      <td>0.277</td>
      <td>0.272</td>
      <td>0.264</td>
      <td>0.252</td>
      <td>0.258</td>
      <td>0.224</td>
      <td>0.089</td>
      <td>0.065</td>
    </tr>
    <tr>
      <td>LabelEq.</td>
      <td style="background-color: #ffff80;">0.600</td>
      <td style="background-color: #ffAA20;">0.706</td>
      <td style="background-color: #ffff80;">0.576</td>
      <td style="background-color: #ffff80;">0.681</td>
      <td>0.277</td>
      <td>-</td>
      <td style="background-color: #ffAA20;">0.814</td>
      <td style="background-color: #ffff80;">0.515</td>
      <td>0.444</td>
      <td>0.404</td>
      <td>0.308</td>
      <td>0.333</td>
      <td>0.121</td>
    </tr>
    <tr>
      <td>Falcon-AO</td>
      <td style="background-color: #ffff80;">0.578</td>
      <td style="background-color: #ffff80;">0.657</td>
      <td style="background-color: #ffff80;">0.562</td>
      <td style="background-color: #ffff80;">0.620</td>
      <td>0.272</td>
      <td style="background-color: #ffAA20;">0.814</td>
      <td>-</td>
      <td>0.468</td>
      <td>0.431</td>
      <td>0.400</td>
      <td>0.300</td>
      <td>0.293</td>
      <td>0.106</td>
    </tr>
    <tr>
      <td>TaxoMap</td>
      <td>0.464</td>
      <td>0.484</td>
      <td>0.443</td>
      <td>0.461</td>
      <td>0.264</td>
      <td style="background-color: #ffff80;">0.515</td>
      <td>0.468</td>
      <td>-</td>
      <td>0.359</td>
      <td>0.432</td>
      <td>0.286</td>
      <td>0.180</td>
      <td>0.104</td>
    </tr>
    <tr>
      <td>AgreementM.</td>
      <td>0.423</td>
      <td>0.435</td>
      <td>0.401</td>
      <td>0.408</td>
      <td>0.252</td>
      <td>0.444</td>
      <td>0.431</td>
      <td>0.359</td>
      <td>-</td>
      <td>0.341</td>
      <td>0.274</td>
      <td>0.166</td>
      <td>0.086</td>
    </tr>
    <tr>
      <td>Prior+</td>
      <td>0.420</td>
      <td>0.416</td>
      <td>0.407</td>
      <td>0.376</td>
      <td>0.258</td>
      <td>0.404</td>
      <td>0.400</td>
      <td>0.432</td>
      <td>0.341</td>
      <td>-</td>
      <td>0.286</td>
      <td>0.139</td>
      <td>0.089</td>
    </tr>
    <tr>
      <td>Lily</td>
      <td>0.349</td>
      <td>0.334</td>
      <td>0.326</td>
      <td>0.297</td>
      <td>0.224</td>
      <td>0.308</td>
      <td>0.300</td>
      <td>0.286</td>
      <td>0.274</td>
      <td>0.286</td>
      <td>-</td>
      <td>0.115</td>
      <td>0.067</td>
    </tr>
    <tr>
      <td>X-Som</td>
      <td>0.205</td>
      <td>0.239</td>
      <td>0.206</td>
      <td>0.232</td>
      <td>0.089</td>
      <td>0.333</td>
      <td>0.293</td>
      <td>0.180</td>
      <td>0.166</td>
      <td>0.139</td>
      <td>0.115</td>
      <td>-</td>
      <td>0.038</td>
    </tr>
    <tr>
      <td>DSSim</td>
      <td>0.109</td>
      <td>0.115</td>
      <td>0.103</td>
      <td>0.106</td>
      <td>0.065</td>
      <td>0.121</td>
      <td>0.106</td>
      <td>0.104</td>
      <td>0.086</td>
      <td>0.089</td>
      <td>0.067</td>
      <td>0.038</td>
      <td>-</td>
    </tr>
  </tbody>

</table>

<p>In particular the low similarity values of comparing systems of type C, indicate that the implemented matching methods differ to a large degree. We expected a significant overlap of the alignment results for these systems, due to common systematic errors and missing background knowledge. Nevertheless, it seems that the systems that generated low f-values &quot;are barking up the wrong tree&quot;, but for all of them it seems to be a different one.</p>


<p>As part of these measurements we also found that AOAS is the only system, that included all correspondences of the trivial label equality approach. Nearly the same holds only for the Falcon-AO system with respect to testcase #3. We have discussed above some reasons for this oddity.</p>

<h2>Other resources</h2>
<p><a href="samples.html">Reference Samples and further results</a></p>


</body>
</html>
